{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import orthogonal_mp\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class image_parser(object):\n",
    "    \n",
    "    def __init__(self,datapath=None,folder=None,images=None,image_names=None,\n",
    "                 min_rows=10,min_cols=10,verbose=False):\n",
    "        self.datapath=datapath\n",
    "        self.folder=folder\n",
    "        self.images=images\n",
    "        self.image_names=image_names\n",
    "        self.min_rows=min_rows\n",
    "        self.min_cols=min_cols\n",
    "        self.verbose=verbose\n",
    "\n",
    "    def read(self):\n",
    "        self.images=np.empty(self.min_rows*self.min_cols)\n",
    "        self.image_names=[]\n",
    "        for base, dirs, files in os.walk (self.datapath+'/'+self.folder+'/'):\n",
    "            for filename in files:\n",
    "                if self.verbose: print(\"reading...\"\n",
    "                                  +self.datapath+'/'+self.folder+'/'+filename)\n",
    "                name_JPEG = re.match (r'^(.*)\\.JPEG$',filename)\n",
    "                if name_JPEG:\n",
    "                    filepath = os.path.join (base, filename)\n",
    "                    image = Image.open (filepath,'r'\n",
    "                                       ).resize((self.min_rows,self.min_cols)).convert(\"L\")\n",
    "                    image = np.array(image).reshape(-1)\n",
    "                    self.images=np.vstack((self.images,image))\n",
    "                    self.image_names.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath=\"/Users/Heather/Desktop/gatech/spring 2016/6240 web search and text mining/project2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the dictionary D with random numbers and normalize the columns.\n",
    "def genDict(num):\n",
    "    D=np.random.random(size=(400, num))\n",
    "    for i in range(num):\n",
    "        D[:,i]=D[:,i]/np.linalg.norm(D[:,i]) \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# following is encoding for animal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "animals=image_parser(folder=\"Animal\",datapath=datapath,\n",
    "                     verbose=False,min_rows=20,min_cols=20)\n",
    "animals.read()\n",
    "\n",
    "# romove the first row which is randomly generated.\n",
    "data=animals.images[1:]/255\n",
    "length=len(data)\n",
    "\n",
    "# divide the data into training data and testing data. We use Transpose to make each column a data sample\n",
    "Y=data.T[:,0:int(length*0.8)]\n",
    "Y_test=data.T[:,int(length*0.8):]\n",
    "D=genDict(800)\n",
    "\n",
    "# use orthogonal matching pursuit algorithm to find X\n",
    "X=orthogonal_mp(D,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update X using orthogonal matching pursuit algorithm\n",
    "def updateX(Y,D):\n",
    "    return orthogonal_mp(D,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the approximation error based on given Y, D and X\n",
    "def Error(Y,D,X):\n",
    "    return np.linalg.norm(Y-D.dot(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update D using K-SVD algorithm\n",
    "def updateD(Y,D,X):\n",
    "    \n",
    "    # initialize the new dictionary\n",
    "    D_update=np.zeros(D.shape)\n",
    "    \n",
    "    for i in range(D.shape[1]):\n",
    "        \n",
    "        # from the whole dataset select data which uses the ith column in the dictionary and only use this part of data to \n",
    "        # update the ith column\n",
    "        X_select=X[:,X[i,:]!=0]\n",
    "        \n",
    "        # if this part is empty, we update the ith column using the data which performs worst according to current dictionary\n",
    "        if(X_select.shape[1]==0):\n",
    "            max_norm=0\n",
    "            p=0\n",
    "            # error matrix:\n",
    "            Error_M=Y-D.dot(X)\n",
    "            # find the vector with largest norm in the error matrix\n",
    "            for k in range(Error_M.shape[1]):\n",
    "                norm=np.linalg.norm(Error_M[:,k])\n",
    "                if norm>max_norm:\n",
    "                    max_norm = norm\n",
    "                    p=k\n",
    "            \n",
    "            # update the ith column of dictionary\n",
    "            D_update[:,i]=Y[:,p]/np.linalg.norm(Y[:,p]) \n",
    "        \n",
    "        # if this part isn't empty, extract the error from this part \n",
    "        else:\n",
    "            Y_new=Y[:,X[i,:]!=0]\n",
    "            X_select[i,:]=0\n",
    "            # error matrix\n",
    "            Error_M=Y_new-D.dot(X_select)\n",
    "            # do SVD on error matrix\n",
    "            U, s, V=np.linalg.svd(Error_M)\n",
    "            # replace the ith column by the first column of U since it catch most variance in the data\n",
    "            D_update[:,i]=U[:,0]\n",
    "            \n",
    "    return D_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.111560165807916"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Error(Y,D,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.2337463313\n",
      "53.8866971475\n",
      "46.4485374423\n",
      "41.6406061438\n",
      "39.4341427901\n",
      "38.6851488448\n",
      "38.3391443761\n",
      "37.7899012816\n",
      "38.8612397783\n",
      "39.9344566316\n",
      "39.4689410998\n",
      "40.8532195598\n",
      "44.3826334797\n",
      "45.8045774933\n",
      "44.9009540147\n",
      "44.7595090793\n",
      "45.7664845419\n",
      "47.0307400315\n",
      "46.8208691099\n",
      "46.3348112512\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    D=updateD(Y,D,X)\n",
    "    X=updateX(Y,D)\n",
    "    print Error(Y,D,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test=updateX(Y_test,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.456659553443302"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test error:\n",
    "Error(Y_test,D,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# following is encoding for Geological Formation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GF=image_parser(folder=\"Geological Formation\",datapath=datapath,\n",
    "                     verbose=False,min_rows=20,min_cols=20)\n",
    "GF.read()\n",
    "data=GF.images[1:]/255\n",
    "length=len(data)\n",
    "Y=data.T[:,0:int(length*0.8)]\n",
    "Y_test=data.T[:,int(length*0.8):]\n",
    "D=genDict(800)\n",
    "X=orthogonal_mp(D,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.680863878782318"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Error(Y,D,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.649544347\n",
      "59.6851816651\n",
      "51.2164930668\n",
      "45.9464719343\n",
      "43.7271564127\n",
      "43.4378373467\n",
      "43.2707195374\n",
      "43.0392165072\n",
      "44.633161527\n",
      "47.0644265809\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    D=updateD(Y,D,X)\n",
    "    X=updateX(Y,D)\n",
    "    print Error(Y,D,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=updateX(Y_test,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.448493255595601"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test error:\n",
    "Error(Y_test,D,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# following is encoding for the mixture of animal and Geological Formation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "animals=image_parser(folder=\"Animal\",datapath=datapath,\n",
    "                     verbose=False,min_rows=20,min_cols=20)\n",
    "animals.read()\n",
    "data1=animals.images[1:]/255\n",
    "\n",
    "# 1 stands for animals\n",
    "data1=np.append(data1,np.ones((data1.shape[0],1)),1)\n",
    "\n",
    "\n",
    "GF=image_parser(folder=\"Geological Formation\",datapath=datapath,\n",
    "                     verbose=False,min_rows=20,min_cols=20)\n",
    "GF.read()\n",
    "data2=GF.images[1:]/255\n",
    "\n",
    "# 0 stands for geological formation\n",
    "data2=np.append(data2,np.zeros((data2.shape[0],1)),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=np.concatenate((data1,data2)).T\n",
    "np.random.shuffle(data.T)\n",
    "length=data.shape[1]\n",
    "Y=data[:,0:int(length*0.8)]\n",
    "Y_test=data[:,int(length*0.8):]\n",
    "D=genDict(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=orthogonal_mp(D,Y[:-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.79280337011205"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Error(Y[:-1,:],D,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.6999335181\n",
      "83.9641940303\n",
      "73.705866032\n",
      "66.9757887887\n",
      "62.6332178486\n",
      "59.9866321084\n",
      "58.4929990043\n",
      "57.5198555972\n",
      "56.5891252133\n",
      "55.6043674915\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    D=updateD(Y[:-1,:],D,X)\n",
    "    X=updateX(Y[:-1,:],D)\n",
    "    print Error(Y[:-1,:],D,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.4149272082769"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test error:\n",
    "X_test=updateX(Y_test[:-1,:],D)\n",
    "Error(Y_test[:-1,:],D,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
