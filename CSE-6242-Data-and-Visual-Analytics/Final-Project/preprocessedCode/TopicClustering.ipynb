{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiajiechen/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 5, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF Clustering based on TFIDF representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"/Users/jiajiechen/Desktop/project-CSE6242/NLP_data\"\n",
    "\n",
    "def read_data(path):\n",
    "    os.chdir(path) #path=data_path\n",
    "    return pd.read_csv(\"TFIDF_model.csv\").values[:,1:],\\\n",
    "           pd.read_csv(\"TFIDF_model.csv\").values[:,0]\n",
    "\n",
    "matrix, users=read_data(path)\n",
    "print(matrix.shape, users.shape)\n",
    "\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=2, init='random',\n",
    "          random_state=1, verbose=0, tol = 1e-10)\n",
    "\n",
    "W = nmf.fit_transform(matrix)\n",
    "H = nmf.components_\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print(W.shape, H.shape, nmf.reconstruction_err_)\n",
    "\n",
    "Cluster = userClusters.values[:,1:]\n",
    "Cluster = normalize(W, norm = 'max',axis=0)\n",
    "\n",
    "nor_userCluster = pd.DataFrame(np.column_stack((user, Cluster)),\n",
    "                               columns=['userID','t1','t2','t3','t4',\n",
    "                                        't5','t6','t7','t8','t9','t10'])\n",
    "\n",
    "print(nor_userCluster.head())\n",
    "\n",
    "words = np.array(pd.read_csv(\"TFIDF_model.csv\").columns[1:])\n",
    "table1 = pd.DataFrame(H, columns = words).transpose()\n",
    "table1.columns = ['t1','t2','t3','t4','t5','t6','t7','t8','t9','t10']\n",
    "\n",
    "def store_result():\n",
    "    table1.to_csv(\"clusterKeywords.csv\",index_label=True)\n",
    "    table1.sort_values(by='t1',axis=0,ascending=False)[['t1']].to_csv(\"clusterKeywords_1.csv\",index_label=True)\n",
    "    table1.sort_values(by='t2',axis=0,ascending=False)[['t2']].to_csv(\"clusterKeywords_2.csv\",index_label=True)\n",
    "    table1.sort_values(by='t3',axis=0,ascending=False)[['t3']].to_csv(\"clusterKeywords_3.csv\",index_label=True)\n",
    "    table1.sort_values(by='t4',axis=0,ascending=False)[['t4']].to_csv(\"clusterKeywords_4.csv\",index_label=True)\n",
    "    table1.sort_values(by='t5',axis=0,ascending=False)[['t5']].to_csv(\"clusterKeywords_5.csv\",index_label=True)\n",
    "    table1.sort_values(by='t6',axis=0,ascending=False)[['t6']].to_csv(\"clusterKeywords_6.csv\",index_label=True)\n",
    "    table1.sort_values(by='t7',axis=0,ascending=False)[['t7']].to_csv(\"clusterKeywords_7.csv\",index_label=True)\n",
    "    table1.sort_values(by='t8',axis=0,ascending=False)[['t8']].to_csv(\"clusterKeywords_8.csv\",index_label=True)\n",
    "    table1.sort_values(by='t9',axis=0,ascending=False)[['t9']].to_csv(\"clusterKeywords_9.csv\",index_label=True)\n",
    "    table1.sort_values(by='t10',axis=0,ascending=False)[['t10']].to_csv(\"clusterKeywords_10.csv\",index_label=True)\n",
    "#end\n",
    "\n",
    "store_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " >  Food: \n",
    "     *  t1, food \n",
    "     *  t7, food+and+cook\n",
    " >  Travel: \n",
    "     *  t6\n",
    " >  Holiday:\n",
    "     *  t2: holiday+weekend+home\n",
    "     *  t4, holiday+xmas+newyear\n",
    "     *  t8, holiday+gift+product\n",
    " >  Tech+HomeDesign:\n",
    "     *  t5, \n",
    " >  SocialNetwork:\n",
    "     *  t10,\n",
    "\n",
    "t3, t9, no meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                         *\n",
    "                                        / \\\n",
    "                                       *   *\n",
    "                                      / \\ / \\\n",
    "* Each node should store info:\n",
    "    * terminal node?\n",
    "    * if not, the cluster assignments, store in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class hierarchicalNMF(object): # under construction\n",
    "    \"\"\"An extension to NMF so that it can be used for hierarchical NMF\"\"\"\n",
    "    class ClusterNode:\n",
    "        \"\"\"A tree structre to store cluster information\"\"\"\n",
    "        def __init__(self, )\n",
    "        \n",
    "    def __init__(self):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nor_userCluster = pd.read_csv(\"nor_userCluster.csv\")\n",
    "influencers = pd.read_csv(\"./data/influencer.csv\")\n",
    "influencers.columns=['userID','userName']\n",
    "\n",
    "influencersTPC=pd.merge(nor_userCluster,influencers, how='right',on='userID')\n",
    "\n",
    "influencersTPC.sort_values(by='t1',axis=0,ascending=False).iloc[:,:2].to_csv(\"./Topics/inferencerRank_t1.csv\",index=None)\n",
    "influencersTPC.sort_values(by='t2',axis=0,ascending=False).iloc[:,[0,2]].to_csv(\"./Topics/inferencerRank_t2.csv\",index=None)\n",
    "influencersTPC.sort_values(by='t4',axis=0,ascending=False).iloc[:,[0,4]].to_csv(\"./Topics/inferencerRank_t4.csv\",index=None)\n",
    "influencersTPC.sort_values(by='t5',axis=0,ascending=False).iloc[:,[0,5]].to_csv(\"./Topics/inferencerRank_t5.csv\",index=None)\n",
    "influencersTPC.sort_values(by='t6',axis=0,ascending=False).iloc[:,[0,6]].to_csv(\"./Topics/inferencerRank_t6.csv\",index=None)\n",
    "influencersTPC.sort_values(by='t7',axis=0,ascending=False).iloc[:,[0,7]].to_csv(\"./Topics/inferencerRank_t7.csv\",index=None)\n",
    "influencersTPC.sort_values(by='t8',axis=0,ascending=False).iloc[:,[0,8]].to_csv(\"./Topics/inferencerRank_t8.csv\",index=None)\n",
    "influencersTPC.sort_values(by='t10',axis=0,ascending=False).iloc[:,[0,10]].to_csv(\"./Topics/inferencerRank_t10.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 0.0198831295134\n",
      "t2 0.0902215072218\n",
      "t4 0.216712747805\n",
      "t5 0.00282034087662\n",
      "t6 0.0124664472437\n",
      "t7 0.0345987960433\n",
      "t8 0.0215500566744\n",
      "t10 0.00676528201649\n"
     ]
    }
   ],
   "source": [
    "print \"t1\", np.percentile(nor_userCluster['t1'],90)\n",
    "print \"t2\", np.percentile(nor_userCluster['t2'],90)\n",
    "print \"t4\", np.percentile(nor_userCluster['t4'],90)\n",
    "print \"t5\", np.percentile(nor_userCluster['t5'],90)\n",
    "print \"t6\", np.percentile(nor_userCluster['t6'],90)\n",
    "print \"t7\", np.percentile(nor_userCluster['t7'],90)\n",
    "print \"t8\", np.percentile(nor_userCluster['t8'],90)\n",
    "print \"t10\", np.percentile(nor_userCluster['t10'],90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
